= Foundation Libraries: Pool & Promises

[abstract]
--
This chapter explores the foundational concurrency libraries that power TaskGraph: the ExecutorPool and Promise frameworks. Understanding these primitives is key to understanding TaskGraph's asynchronous execution model.
--

== Overview

TaskGraph is built on two fundamental concurrency libraries located in the `org.softwood.pool` and `org.softwood.promise` packages:

* **ExecutorPool** - Managed thread pools with lifecycle control
* **Promise/Future** - Asynchronous value containers with composition support

These libraries provide the low-level primitives that TaskGraph uses to orchestrate concurrent workflow execution.

== ExecutorPool Framework

The ExecutorPool framework (`org.softwood.pool.*`) provides managed thread pools with automatic resource management.

=== Virtual Threads by Default (Java 21+)

**IMPORTANT: TaskGraph uses Java Virtual Threads by default - no configuration required!**

TaskGraph leverages Java 21+ virtual threads as the natural, optimal choice for concurrent task execution:

[source,groovy]
----
// Default behavior - uses virtual threads automatically
def workflow = TaskGraph.build {
    task("my-task") {
        action { performWork() }
    }
}

// Internally uses virtual thread executor - nothing to configure!
workflow.start()  // Tasks execute on virtual threads
----

**Why Virtual Threads?**

* **Lightweight** - Millions of virtual threads vs thousands of platform threads
* **No blocking penalty** - Blocking operations don't tie up OS threads
* **Natural scalability** - Perfect for I/O-heavy workflows
* **No tuning needed** - Works optimally out-of-the-box

**The default pool uses virtual threads automatically:**

[source,groovy]
----
// This is what TaskGraph does by default (you don't need to do this!)
def pool = ExecutorPoolFactory.defaultPool()
// Returns: Executors.newVirtualThreadPerTaskExecutor()
// Auto-detected when running on Java 21+

// Your workflows just work with virtual threads:
def workflow = TaskGraph.build {
    // All 1000 tasks run concurrently on virtual threads - no problem!
    (1..1000).each { i ->
        httpTask("api-call-${i}") {
            url "https://api.example.com/item/${i}"
        }
    }
}
----

=== ExecutorPoolFactory - Named Pool Instances

While virtual threads are the default, you can create custom named pool instances for specific use cases:

==== Default Pool (Virtual Threads)

[source,groovy]
----
// Get the default virtual thread pool
def pool = ExecutorPoolFactory.defaultPool()

// On Java 21+: Returns virtual thread executor
// On Java 17-20: Returns ForkJoinPool.commonPool()

// Use in TaskGraph (already the default!)
def workflow = TaskGraph.build {
    executorPool pool  // Unnecessary - this is already the default

    task("my-task") { action { work() } }
}
----

==== Named Pool Instances

Create named pool instances for specific purposes:

[source,groovy]
----
// Create named pools for different workload types
class MyPools {
    // Virtual thread pool for I/O operations (recommended)
    static final ExecutorPool IO_POOL =
        ExecutorPoolFactory.newVirtualThreadPool("io-operations")

    // Virtual thread pool for API calls (recommended)
    static final ExecutorPool API_POOL =
        ExecutorPoolFactory.newVirtualThreadPool("api-calls")

    // Platform thread pool for CPU-intensive work (if needed)
    static final ExecutorPool CPU_POOL =
        ExecutorPoolFactory.newFixedThreadPool(
            Runtime.availableProcessors(),
            "cpu-intensive"
        )

    // Named scheduled pool for periodic tasks
    static final ExecutorPool SCHEDULER =
        ExecutorPoolFactory.newScheduledThreadPool(2, "scheduler")
}

// Use named pools in workflows
def workflow = TaskGraph.build {
    httpTask("api-call") {
        executorPool MyPools.API_POOL  // Use named API pool
        url "https://api.example.com/data"
    }

    task("cpu-work") {
        executorPool MyPools.CPU_POOL  // Use named CPU pool
        action { cpuIntensiveCalculation() }
    }
}
----

==== Creating Custom Named Pools

[source,groovy]
----
// Virtual thread pool (recommended for most use cases)
def ioPool = ExecutorPoolFactory.newVirtualThreadPool("database-operations")

// Platform thread pools (for specific needs)
def fixedPool = ExecutorPoolFactory.newFixedThreadPool(10, "fixed-workers")
def cachedPool = ExecutorPoolFactory.newCachedThreadPool("dynamic-workers")
def singlePool = ExecutorPoolFactory.newSingleThreadExecutor("sequential-processor")

// Scheduled pool
def scheduledPool = ExecutorPoolFactory.newScheduledThreadPool(5, "scheduled-tasks")
scheduledPool.schedule({ println "Delayed" }, 10, TimeUnit.SECONDS)
scheduledPool.scheduleAtFixedRate({ println "Periodic" }, 0, 5, TimeUnit.SECONDS)

// All pools implement ExecutorPool interface
interface ExecutorPool {
    String getName()  // Pool name for monitoring
    Future<?> submit(Runnable task)
    <T> Future<T> submit(Callable<T> task)

    // Lifecycle
    void shutdown()
    List<Runnable> shutdownNow()
    boolean awaitTermination(long timeout, TimeUnit unit)

    // Statistics
    int getActiveCount()
    int getPoolSize()
    long getCompletedTaskCount()
}
----

=== When to Use Custom Pools

**Use the default virtual thread pool (already configured) when:**
* ✅ Tasks perform I/O operations (HTTP, database, file operations)
* ✅ Tasks block on external resources
* ✅ You have many concurrent tasks (hundreds to millions)
* ✅ You want zero-configuration optimal performance

**Consider custom named pools for:**
* **CPU-intensive work** - Fixed platform thread pool sized to CPU cores
* **Sequential processing** - Single thread executor for ordered execution
* **Scheduled tasks** - Scheduled thread pool for cron-like operations
* **Resource isolation** - Separate pools for different subsystems
* **Monitoring** - Named pools for better observability

[source,groovy]
----
// Example: Different pools for different workloads
def workflow = TaskGraph.build {
    // I/O tasks use default virtual threads (optimal)
    httpTask("fetch-data") {
        // No executorPool specified - uses default virtual threads
        url "https://api.example.com/data"
    }

    sqlTask("query-db") {
        // No executorPool specified - uses default virtual threads
        query "SELECT * FROM users"
    }

    // CPU-intensive task uses platform thread pool
    task("crunch-numbers") {
        executorPool MyPools.CPU_POOL  // Custom platform thread pool
        action {
            // Computation-heavy work
            complexMathematicalCalculation()
        }
    }

    // Ordered processing uses single thread executor
    task("sequential") {
        executorPool MyPools.SEQUENTIAL_POOL
        action {
            // Must be processed in order
            processInOrder()
        }
    }
}
----

=== Pool Configuration (Advanced)

For the rare cases where you need custom platform thread pool configuration:

[source,groovy]
----
import org.softwood.pool.*

// Custom platform thread pool configuration
// (Most users should use virtual threads instead!)
def config = PoolConfig.builder()
    .poolName("custom-platform-pool")
    .corePoolSize(10)
    .maxPoolSize(50)
    .keepAliveTime(60, TimeUnit.SECONDS)
    .queueCapacity(1000)
    .threadNamePrefix("workflow-")
    .rejectionPolicy(RejectionPolicy.CALLER_RUNS)
    .build()

def customPool = ExecutorPoolFactory.create(config)

// Use in specific tasks that need platform threads
task("legacy-blocking-io") {
    executorPool customPool
    action { legacyBlockingOperation() }
}
----

**Configuration options for platform thread pools:**

* `poolName` - Named identifier for monitoring
* `corePoolSize` - Minimum threads kept alive
* `maxPoolSize` - Maximum threads allowed
* `keepAliveTime` - How long excess threads stay alive
* `queueCapacity` - Bounded queue size (0 = unbounded)
* `threadNamePrefix` - Name pattern for threads
* `rejectionPolicy` - What to do when queue is full

**Rejection Policies:**

[cols="1,3"]
|===
|Policy |Behavior

|`ABORT`
|Throw `RejectedExecutionException` (default)

|`CALLER_RUNS`
|Execute in the calling thread (provides backpressure)

|`DISCARD`
|Silently discard the task

|`DISCARD_OLDEST`
|Discard oldest queued task, retry
|===

NOTE: Virtual thread pools don't need these configurations - they scale automatically!

=== Pool Usage in TaskGraph

TaskGraph uses the default virtual thread pool automatically, but you can override at different levels:

==== Default Behavior (Recommended)

Just use TaskGraph - virtual threads work automatically:

[source,groovy]
----
// This is all you need - virtual threads are used automatically!
def workflow = TaskGraph.build {
    task("step1") { action { fetchData() } }
    task("step2") { action { processData() } }
}

// Tasks run on virtual threads - perfect for I/O and blocking operations
workflow.start()
----

==== Graph-Level Pool Override

Override the pool for an entire graph (rarely needed):

[source,groovy]
----
// Only if you have specific requirements
def namedPool = ExecutorPoolFactory.newVirtualThreadPool("my-workflow-pool")

def workflow = TaskGraph.build {
    executorPool namedPool  // All tasks use this pool

    task("step1") { action { work1() } }
    task("step2") { action { work2() } }
}
----

==== Task-Level Pool Override

Individual tasks can use different named pools:

[source,groovy]
----
// Create named pools for different purposes
def ioPool = ExecutorPoolFactory.newVirtualThreadPool("io-operations")
def cpuPool = ExecutorPoolFactory.newFixedThreadPool(
    Runtime.availableProcessors(),
    "cpu-intensive"
)

TaskGraph.build {
    // I/O task uses named virtual thread pool
    task("io-bound") {
        executorPool ioPool  // Named virtual thread pool
        action { performIO() }
    }

    // CPU task uses platform thread pool
    task("cpu-bound") {
        executorPool cpuPool  // Platform thread pool for CPU work
        action { cpuIntensiveCalculation() }
    }

    // This task uses the default virtual thread pool
    task("default") {
        action { normalWork() }  // Uses default virtual threads
    }
}
----

=== Pool Monitoring

Monitor named pool instances for observability:

[source,groovy]
----
// Create named pool for monitoring
def pool = ExecutorPoolFactory.newVirtualThreadPool("api-operations")

// Get pool name
println "Pool: ${pool.name}"  // "api-operations"

// Get statistics (varies by pool type)
println "Active count: ${pool.activeCount}"
println "Completed tasks: ${pool.completedTaskCount}"

// For platform thread pools only:
def platformPool = ExecutorPoolFactory.newFixedThreadPool(10, "platform-pool")
println "Pool size: ${platformPool.poolSize}"
println "Queue size: ${platformPool.queue.size()}"
----

=== Best Practices

**1. Use virtual threads by default (no configuration needed!):**
[source,groovy]
----
// ✅ Best practice - just use TaskGraph
def workflow = TaskGraph.build {
    task("my-task") { action { work() } }
}
// Virtual threads handle everything optimally!
----

**2. Create named pools for monitoring and isolation:**
[source,groovy]
----
// ✅ Good - named pools for observability
def apiPool = ExecutorPoolFactory.newVirtualThreadPool("external-api-calls")
def dbPool = ExecutorPoolFactory.newVirtualThreadPool("database-operations")
def scheduledPool = ExecutorPoolFactory.newScheduledThreadPool(2, "scheduled-tasks")

// Pool names appear in logs, metrics, and monitoring dashboards
----

**3. Use platform thread pools only for CPU-intensive work:**
[source,groovy]
----
// ✅ Good - platform threads for CPU work only
def cpuPool = ExecutorPoolFactory.newFixedThreadPool(
    Runtime.availableProcessors(),
    "cpu-intensive"
)

task("crunch-numbers") {
    executorPool cpuPool  // CPU-bound work
    action { complexCalculation() }
}

// ❌ Bad - platform threads for I/O (use virtual threads instead!)
def badPool = ExecutorPoolFactory.newFixedThreadPool(100, "io-tasks")
----

**4. Size platform thread pools appropriately (virtual threads don't need sizing):**

* **Virtual threads** - No sizing needed! Use for I/O and blocking operations
* **CPU-bound platform threads** - `Runtime.availableProcessors()` or `CPUs + 1`
* **Scheduled tasks** - Small fixed number (2-5 threads)

**5. Always shut down custom pools (virtual threads auto-cleanup on JVM exit):**
[source,groovy]
----
// Custom platform thread pool requires manual shutdown
def customPool = ExecutorPoolFactory.newFixedThreadPool(10, "custom")
try {
    // Use pool
} finally {
    customPool.shutdown()
    customPool.awaitTermination(30, TimeUnit.SECONDS)
}

// Virtual thread pools automatically clean up
def vtPool = ExecutorPoolFactory.newVirtualThreadPool("vt-pool")
// No shutdown needed - cleaned up on JVM exit
----

**6. Don't worry about pool exhaustion with virtual threads:**
[source,groovy]
----
// ✅ With virtual threads - no problem!
def workflow = TaskGraph.build {
    // 10,000 concurrent tasks? No problem with virtual threads!
    (1..10000).each { i ->
        httpTask("api-${i}") {
            url "https://api.example.com/item/${i}"
        }
    }
}

// ❌ With platform threads - would need careful sizing
// Don't do this - use virtual threads instead!
def platformPool = ExecutorPoolFactory.newFixedThreadPool(10000, "bad-idea")
----

== Promise Framework

The Promise framework (`org.softwood.promise.*`) provides asynchronous value containers with functional composition.

=== Core Concepts

==== Promise vs Future

**Future** (Java standard)::
Blocking placeholder for a future value.
+
[source,groovy]
----
Future<String> future = executor.submit({ "Hello" })
String result = future.get()  // ❌ Blocks thread
----

**Promise** (TaskGraph)::
Non-blocking, composable async value.
+
[source,groovy]
----
Promise<String> promise = Promises.task(pool) { "Hello" }
promise.then { result ->
    println result  // ✅ Non-blocking callback
}

// Virtual thread pools automatically clean up
def vtPool = ExecutorPoolFactory.newVirtualThreadPool("vt-pool")
// No shutdown needed - cleaned up on JVM exit
----

=== Creating Promises

==== Task Promises

Execute async work in a pool:

[source,groovy]
----
import org.softwood.promise.Promises

def pool = ExecutorPoolFactory.defaultPool()

def promise = Promises.task(pool) {
    // Async work
    Thread.sleep(1000)
    return "Result"
}
----

==== Completed Promises

Return an already-resolved value:

[source,groovy]
----
// Success
def success = Promises.successful("immediate value")

// Failure
def failure = Promises.failed(new RuntimeException("error"))
----

==== Deferred Promises

Manual control over completion:

[source,groovy]
----
def deferred = Promises.deferred()

// Complete later
Thread.start {
    Thread.sleep(1000)
    deferred.resolve("value")
    // or: deferred.reject(error)
}

def promise = deferred.promise
----

=== Promise Composition

==== Sequential Composition

Chain operations with `then`:

[source,groovy]
----
Promises.task(pool) {
    fetchUser(123)
}.then { user ->
    fetchOrders(user.id)
}.then { orders ->
    calculateTotal(orders)
}.then { total ->
    println "Total: $total"
}
----

==== Transformation

Transform values with `map`:

[source,groovy]
----
Promises.task(pool) {
    fetchData()
}.map { data ->
    data.toUpperCase()  // Transform
}.map { upper ->
    upper.size()  // Transform again
}
----

==== Error Recovery

Handle errors with `recover` or `fallbackTo`:

[source,groovy]
----
// Recover from error
Promises.task(pool) {
    riskyOperation()
}.recover { error ->
    log.error("Failed: $error")
    return "fallback value"
}

// Fallback to alternative promise
def primary = Promises.task(pool) { fetchFromPrimary() }
def secondary = Promises.task(pool) { fetchFromSecondary() }

primary.fallbackTo(secondary)
----

==== Parallel Composition

Wait for multiple promises:

[source,groovy]
----
def p1 = Promises.task(pool) { fetchUsers() }
def p2 = Promises.task(pool) { fetchOrders() }
def p3 = Promises.task(pool) { fetchProducts() }

// All must succeed
Promises.all([p1, p2, p3]).then { results ->
    def (users, orders, products) = results
    println "Fetched: $users.size() users, $orders.size() orders"
}

// First to complete
Promises.race([p1, p2, p3]).then { first ->
    println "First result: $first"
}

// All settled (success or failure)
Promises.allSettled([p1, p2, p3]).then { results ->
    results.each { result ->
        if (result.isSuccess()) {
            println "Success: ${result.value}"
        } else {
            println "Failed: ${result.error}"
        }
    }
}
----

=== Promise Operations

==== Filter

Filter based on predicate:

[source,groovy]
----
Promises.task(pool) {
    fetchNumber()
}.filter { n ->
    n > 0  // Only accept positive numbers
}.then { positive ->
    println "Positive: $positive"
}.recover { error ->
    println "Filtered out or error"
}
----

==== Zip

Combine two promises:

[source,groovy]
----
def p1 = Promises.task(pool) { fetchUser() }
def p2 = Promises.task(pool) { fetchProfile() }

p1.zip(p2) { user, profile ->
    return [user: user, profile: profile]
}.then { combined ->
    println combined
}
----

==== FlatMap

Chain async operations:

[source,groovy]
----
Promises.task(pool) {
    fetchUserId()
}.flatMap { userId ->
    // Return another promise
    Promises.task(pool) {
        fetchUser(userId)
    }
}.then { user ->
    println user
}
----

==== OnComplete

Execute side effects (success or failure):

[source,groovy]
----
promise
    .onComplete { result ->
        println "Completed: $result"
    }
    .onSuccess { value ->
        println "Success: $value"
    }
    .onError { error ->
        log.error("Error: $error")
    }
----

=== Timeout and Cancellation

==== Timeout

Fail promise if not completed in time:

[source,groovy]
----
Promises.task(pool) {
    slowOperation()
}.timeout(5, TimeUnit.SECONDS)
  .recover { error ->
      if (error instanceof TimeoutException) {
          log.warn("Timed out after 5s")
          return "default"
      }
      throw error
  }
----

==== Cancellation

Cancel ongoing work:

[source,groovy]
----
def promise = Promises.task(pool) {
    longRunningOperation()
}

// Cancel after 2 seconds
Thread.start {
    Thread.sleep(2000)
    promise.cancel()
}

promise.onError { error ->
    if (error instanceof CancellationException) {
        println "Cancelled"
    }
}
----

=== Promise Usage in TaskGraph

TaskGraph uses promises internally for all task execution:

==== Task Execution Returns Promise

[source,groovy]
----
def workflow = TaskGraph.build {
    task("step1") {
        action { "result" }
    }
}

// Start returns Promise<GraphResult>
def promise = workflow.start()

// Non-blocking callback
promise.then { result ->
    println "Workflow completed"
    println "Results: ${result.taskResults}"
}

// Or block if needed
def result = promise.get()
----

==== Individual Task Promises

[source,groovy]
----
def task = workflow.getTask("step1")
def taskPromise = task.start()

taskPromise.then { result ->
    println "Task result: $result"
}
----

==== Combining Task Promises

[source,groovy]
----
def task1 = workflow.getTask("fetch-users")
def task2 = workflow.getTask("fetch-orders")

def p1 = task1.start()
def p2 = task2.start()

Promises.all([p1, p2]).then { results ->
    println "Both completed: $results"
}
----

=== Best Practices

**1. Avoid blocking operations:**
[source,groovy]
----
// ❌ Bad - blocks thread
def result = promise.get()

// ✅ Good - non-blocking
promise.then { result ->
    // Handle result
}
----

**2. Always handle errors:**
[source,groovy]
----
promise
    .then { result -> /* ... */ }
    .onError { error -> log.error("Failed", error) }
----

**3. Use composition over callbacks:**
[source,groovy]
----
// ❌ Callback hell
promise.then { r1 ->
    Promises.task(pool) {
        process(r1)
    }.then { r2 ->
        Promises.task(pool) {
            save(r2)
        }.then { r3 ->
            println r3
        }
    }
}

// ✅ Composed
promise
    .flatMap { r1 -> Promises.task(pool) { process(r1) } }
    .flatMap { r2 -> Promises.task(pool) { save(r2) } }
    .then { r3 -> println r3 }
----

**4. Set timeouts for external operations:**
[source,groovy]
----
Promises.task(pool) {
    callExternalAPI()
}.timeout(30, TimeUnit.SECONDS)
----

== Dataflow Variables

The `org.softwood.dataflow` package provides single-assignment variables for coordinating concurrent tasks.

=== DataflowVariable

A variable that can be written once and read many times:

[source,groovy]
----
import org.softwood.dataflow.DataflowVariable

def var = new DataflowVariable()

// Write once
Thread.start {
    Thread.sleep(1000)
    var.bind("value")  // Single assignment
}

// Read blocks until value available
println var.get()  // Waits for binding
----

=== Usage Patterns

==== Producer-Consumer

[source,groovy]
----
def result = new DataflowVariable()

// Producer
Thread.start {
    def data = fetchData()
    result.bind(data)
}

// Multiple consumers
10.times { i ->
    Thread.start {
        def data = result.get()  // All get same value
        process(data, i)
    }
}
----

==== Synchronization Point

[source,groovy]
----
def barrier = new DataflowVariable()

// Workers wait for signal
def workers = (1..10).collect { i ->
    Thread.start {
        barrier.get()  // Wait for start signal
        doWork(i)
    }
}

// Coordinator starts work
Thread.sleep(1000)
barrier.bind("GO")  // Release all workers
----

=== TaskGraph Usage

TaskGraph uses dataflow variables internally for dependency coordination:

[source,groovy]
----
// TaskGraph implementation (simplified)
class TaskBase {
    DataflowVariable result = new DataflowVariable()

    void execute() {
        // Wait for dependencies
        predecessors.each { pred ->
            pred.result.get()  // Blocks until predecessor completes
        }

        // Execute task
        def value = performTask()

        // Publish result
        result.bind(value)
    }
}
----

== Integration: How It All Works Together

=== Task Execution Flow

[plantuml, execution-flow, svg]
....
@startuml
participant "TaskGraph" as TG
participant "Task" as Task
participant "ExecutorPool" as Pool
participant "Promise" as Promise
participant "DataflowVariable" as DFV

TG -> Task: start()
Task -> DFV: wait for dependencies
DFV --> Task: dependencies complete

Task -> Pool: submit(taskLogic)
Pool --> Promise: return Promise
Task --> TG: return Promise

Pool -> Task: execute in thread
Task -> Promise: complete(result)
Promise -> DFV: bind(result)

DFV -> Task: notify successors
@enduml
....

=== Example: Complete Flow with Virtual Threads

[source,groovy]
----
// 1. No pool creation needed - virtual threads by default!

// 2. Define workflow - uses virtual threads and promises automatically
def workflow = TaskGraph.build {
    // No executorPool config needed!

    task("fetch") {
        action {
            // Executes on virtual thread, returns Promise
            fetchData()
        }
    }

    task("process") {
        dependsOn "fetch"
        action { ctx ->
            // Waits for "fetch" via DataflowVariable
            def data = ctx.prev

            // Process and return Promise (on virtual thread)
            processData(data)
        }
    }
}

// 3. Start returns Promise<GraphResult>
def promise = workflow.start()

// 4. Compose with promise operations
promise
    .timeout(60, TimeUnit.SECONDS)
    .then { result ->
        println "Success: ${result.taskResults}"
    }
    .onError { error ->
        log.error("Failed", error)
    }

// Or block for result
def result = promise.get()
----

== Performance Considerations

=== Virtual Threads - No Pool Sizing Required!

**Virtual threads scale automatically - no tuning needed:**

[source,groovy]
----
// ✅ Perfect - handles any number of concurrent tasks
def workflow = TaskGraph.build {
    // 10,000 concurrent HTTP calls? No problem!
    (1..10000).each { i ->
        httpTask("api-${i}") {
            url "https://api.example.com/item/${i}"
        }
    }
}

// All tasks run concurrently on virtual threads
// No pool exhaustion, no careful sizing - it just works!
----

**Virtual threads are optimal for:**
* HTTP/REST API calls
* Database operations
* File I/O
* Message queue operations
* Any blocking operations

=== Platform Thread Pool Sizing (CPU-Intensive Only)

**Only needed for CPU-bound work:**

[source,groovy]
----
// CPU-intensive: size to CPU cores
def cpuPool = ExecutorPoolFactory.newFixedThreadPool(
    Runtime.availableProcessors(),
    "cpu-work"
)

task("computation") {
    executorPool cpuPool
    action { cpuIntensiveCalculation() }
}
----

**Don't use platform threads for I/O:**
[source,groovy]
----
// ❌ Bad - wasteful, limits scalability
def badPool = ExecutorPoolFactory.newFixedThreadPool(1000, "io-tasks")

// ✅ Good - virtual threads for I/O (the default!)
def workflow = TaskGraph.build {
    // No pool config - uses virtual threads automatically
    httpTask("api") { url "..." }
}
----

=== Promise Overhead

Promises have minimal overhead:

* **Creation:** ~100 nanoseconds
* **Composition:** ~50 nanoseconds per operation
* **Memory:** ~200 bytes per promise

For very high-throughput scenarios (millions of ops/sec), consider pooling or reusing promises.

=== Dataflow Performance

DataflowVariable operations:

* **Bind:** O(1) time, notifies all waiters
* **Get (bound):** O(1) immediate return
* **Get (unbound):** Blocks until bound

== Debugging and Monitoring

=== Thread Dumps

Identify pool exhaustion:

[source,groovy]
----
// Get thread dump
def threadDump = Thread.allStackTraces
    .findAll { thread, stack ->
        thread.name.startsWith("workflow-")
    }

threadDump.each { thread, stack ->
    println "${thread.name} - ${thread.state}"
    stack.take(5).each { println "  $it" }
}
----

=== Promise Tracing

Enable detailed promise logging:

[source,groovy]
----
System.setProperty("promise.trace", "true")

Promises.task(pool) {
    operation()
}.then { result ->
    // Logs: Promise[123] completed with: result
    result
}
----

=== Pool Metrics

Export pool metrics:

[source,groovy]
----
def pool = ExecutorPoolFactory.defaultPool()

def metrics = [
    active: pool.activeCount,
    poolSize: pool.poolSize,
    coreSize: pool.corePoolSize,
    maxSize: pool.maximumPoolSize,
    completed: pool.completedTaskCount,
    queueSize: pool.queue.size(),
    largestPoolSize: pool.largestPoolSize
]

println JsonOutput.toJson(metrics)
----

== Summary

The foundation libraries provide:

* ✅ **ExecutorPool** - Managed thread pools with lifecycle control
* ✅ **Promise** - Non-blocking async values with composition
* ✅ **Dataflow** - Single-assignment coordination primitives
* ✅ **Integration** - Seamless TaskGraph integration
* ✅ **Performance** - Low-overhead, high-throughput
* ✅ **Observability** - Built-in monitoring and debugging

These primitives are the building blocks that enable TaskGraph's powerful asynchronous orchestration capabilities.

== Next Steps

* **Chapter 4** - Learn how Tasks, TaskCollections, and TaskGraph build on these foundations
* **Chapter 6** - Understand how TaskContext provides execution context
* **Appendix B** - Performance tuning guidelines
